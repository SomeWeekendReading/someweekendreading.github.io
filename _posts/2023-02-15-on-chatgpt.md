---
layout: post
title: On ChatGPT and Its Ilk
tags: ArtificialIntelligence CorporateLifeAndItsDiscontents NotableAndQuotable Sadness
comments: true
commentsClosed: true
---

Somebody just summarized for me the _exact_ nature of ChatGPT.  


## Chat _what?_  

Just in case you've been sleeping under a rock for the last couple years, there's this
thing called [ChatGPT](https://www.chatgptonline.net/):  
- "GPT" stands for "Generative Pretrained Transformer", i.e., involving what's now called
  a "Large Language Model".  
- It's a giant recursive neural net &ndash; with a large variety of tweaks &ndash; trained
  (more or less) on text scraped from the entire Internet.  
- It works as a probabilistic model of text, suggesting what might be a plausible
  completion of a prompt.  (There are safeguards against people training it to write porn
  or fascist or racist texts.  These "safeguards" are laughably weak and easily evaded by
  schoolchildren.)  
- The "Chat" version above is a web-interfaced version of GPT-3.5 (as of today), where you
  can make a free account and ask it questions.  
  
The responses are _amazing,_ for both good and bad meanings of that word:  
- On the one hand, they are _very_ persuasive.  You'd really think a person, or person-like
  thing, generated the text.  It's good enough that people actually propose using it as a
  substitute for search engines like Google.  
- On the other hand, that is a _terrible_ idea!  It is optimized for plausibility, not for
  truth.  The generated text is riddled with errors and what are described as
  "hallucinations".  But they're all so plausible, _you can't tell which is which._  

When I asked it a technical question, it made a very plausible-sounding argument, complete
with citations to the relevant scientific literature.  I was really impressed: the papers
it cited were by famous scientists working in the correct area, published in important journals,
with titles that were spot-on relevant to my interests.  So why hadn't I, as a scientist
familiar with the area, already read those papers?  __Because they were all fake!__ Every
single one was an hallucination, absolutely bereft of existence.  


## So&hellip; what?  

What do you call a person who is very good at sounding persuasive and plausible, but
absolutely bereft of fidelity to fact?  A BS artist.  (Yes, the aversive conditioning of
my mis-spent childhood to this day prevent me from violating the "swearing" taboo that my
elders learned more than a century ago, and imposed on me.)  

And I was thinking that this was a good description of ChatGPT.  Then, via
[PZMyers on Mastodon](https://octodon.social/@pzmyers) I saw this perfect summary of the
situation by [Blake C Stacey](https://icosahedron.website/@bstacey), a theoretical
physicist at UMass Boston (practically a neighbor!) <sup id="fn1a">[[1]](#fn1)</sup>:  

<a href="https://icosahedron.website/@bstacey/109798526271267537"><img src="{{ site.baseurl }}/images/2023-02-15-on-chatgpt-stacey-1.jpg" width="550" height="820" alt="Stacey @ Mastodon: ChatGPT as BS fountain" title="Stacey @ Mastodon: ChatGPT as BS fountain" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;"></a>

Yes!  Exactly!  The first step is to recognize a sewage outfall pipe when you see/smell one.
The next step is to be elsewhere.

(Another interesting take on ChatGPT was
"[mansplaining](https://en.wikipedia.org/wiki/Mansplaining) as a service", which is pretty
good too.)  

__NB:__ None of this is to take away from the _technical_ achievement of ChatGPS, and the
scientists &amp; engineers behind it.  This is clearly a work of high-quality craft, from
high-quality craftspeople.  It's just that "make plausible BS with no allegiance to truth" is
kind of a&hellip; _peculiar_ goal if you're trying to make something useful.  (But totally
understandable if you're in the pay of fascist propagandists?  I _really_ hope that's not
the case!)  


## The Weekend Conclusion  

We desperately need a well-trained
[supervised classifier](https://en.wikipedia.org/wiki/Supervised_learning)
that can identify such generated texts, and tag them so people know better than to take
them at face value.  Probably should be done as a browser plug-in, so you see
"WARNING: AI-GENERATED BS" in large, friendly red letters when you encounter some on the
web.  (Imagine what it would do to a real-time text feed of politicians speaking.)  

The _last_ thing we need is highly automatable, high quality BS to deceive the public in a
time of rising fascism.  

---

## Notes &amp; References  

<!--
<sup id="fn1a">[[1]](#fn1)</sup>

<a id="fn1">1</a>: ***, ["***"](***), *** [↩](#fn1a)  

<a href="{{ site.baseurl }}/images/***">
  <img src="{{ site.baseurl }}/images/***" width="400" height="***" alt="***" title="***" style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<a href="***">
  <img src="{{ site.baseurl }}/images/***" width="550" height="***" alt="***" title="***" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<iframe width="400" height="224" src="***" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;"></iframe>
-->

<a id="fn1">1</a>: Apparently, he also writes [fanfiction](https://archiveofourown.org/users/BlakeStacey/).  So, you know, there's that. (Hey, guilty pleasures are still pleasures.  Don't judge me.  Or him.  At least, not for _that._) [↩](#fn1a)  
