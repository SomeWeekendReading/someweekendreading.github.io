---
layout: post
title: On using ChatGPT for Peer Review
tags: ArtificialIntelligence NotableAndQuotable Sadness SomebodyAskedMe Statistics &Gammad;&Tau;&Phi;
comments: true
commentsClosed: true
---

Somebody submitted a paper to a journal.  The journal sent it out for peer review.
A reviewer, skimping on their job, used ChatGPT to write the review.  This went about as
well as you probably think.  


## How Publishing an Academic Paper Works (or, Is Supposed To Work!)  

Let's look at the way things are _supposed_ to work (and often _do_ work, very approximately):  
- You, after many long years, finally codify your Grand Unified Theory of Pastry into a
  simple 10-pager that lets mundanes in on your particular _gnosis_.  
- You send this off to a prominent journal in your field, the
  _Journal of Post-Modern [Psycho-Ceramics](https://en.wiktionary.org/wiki/psychoceramics)._  
 The editor of _Jnl PoMo P-C_, the eminent
  [Josiah Stinkney Carberry](https://en.wikipedia.org/wiki/Josiah_S._Carberry) gives it a
  quick once-over, and thinks it might be worth looking into.  So your paper goes into
  their tracking system and then out to a panel of peer reviewers.  
- The peer reviewers are a panel of several other scholars in your field, just as crazy as
  you.  They each independently, and ideally without knowing you are the author, review
  the paper.  They assess it:  
  - Does this even make sense?  
  - Is it right, or at least very likely right?  
  - Is it timely, i.e., solving a problem about which other scholars even care?  
  - Is it reasonably clear?  
  - Is it relevant to the readership of _Jnl PoMo P-C_?  
- If that comes up mostly "yes", then your paper is published.  Done!  
- Otherwise, the editor guesses whether there's any hope of making it better:  
  - If not, your paper is finally rejected, with the unspoken suggestion that you never
    darken their door ever again.  
  - If it's kinda ok, but not on topic, they may suggest a different journal for you to
    try, or just tell you to find one yourself.  Beware if they suggest the
	[_Journal of Irreproducible Results_](https://en.wikipedia.org/wiki/Journal_of_Irreproducible_Results).  
  - If it's kinda ok but just needs some improvement, you get it back with "suggested"
    changes, some of which come from the reviewers.  
- You look the situation over, and either give up or "revise &amp; resubmit."  

This is supposed to result in scientific literature that is up-to-date, accurate,
understandable, and relevant.  You can have various opinions about this.  

## Today's example  

Now, you might understand that here at Ch&acirc;teau Weekend we have a somewhat jaundiced
view of these Large Language Model gizmos, and their tendency to hallucinate, resulting in
convincing, bogus text. <sup id="fn1a">[[1]](#fn1)</sup> (Best take heard since then: even
when they're right, it's by accident since they have no notion of truth.  So they're
_always_ hallucinating, nonstop.)  

Today's example comes from a [LinkedIn](https://www.linkedin.com/) post by an academic named
Robin Bawens <sup id="fn2a">[[2]](#fn2)</sup>:  

<a href="https://www.linkedin.com/feed/update/urn:li:share:7046083155149103105/"><img src="{{ site.baseurl }}/images/2023-06-15-chatgpt-vs-peer-review-baudens-1.jpg" width="550" height="630" alt="Bawens @ LinkedIn: Abuse of GPT in peer review" title="Bawens @ LinkedIn: Abuse of GPT in peer review" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;"></a>

Yeesh&hellip;  let's unpack this.  So Bauwens submitted a paper, which the journal sent
out for peer review.  

So far, so good.  

But one of the reviewers rejected the paper, "suggesting" Bauwens familiarize himself
with several other papers before trying again.  This _can_ be meant helpfully, or it can
be snarky as in "You're too ignorant to publish here, so let me send you on a wild-goose
chase by way of tutorial."  

I this case, it was even worse: the references, of course, did not exist!  This is
[exactly what we documented before](http://localhost:4000/on-chatgpt/#:~:text=When%20I%20asked,bereft%20of%20existence.),
with regard to hallucinated references.  Since then, we've heard from academics frustrated
with people requesting papers they never wrote.  One particularly clever wag pointed out
that given how LLMs work, hallucinations are _normal_ and it would be astounding if it
came up with _real_ references!  

So, suspicious that this might be what the reviewer did, Bawens wisely checked.  The
suggested tutorial references were all fabrications of GPT-2.  

The reviewer had, in fact, not reviewed the paper.  He'd fed it to something like ChatGPT
and asked it to write a rejection letter!  

Ever-so-slightly gratifyingly, Bauwens reports that when he showed this to the journal
editor, that aberrant peer reviewer was dropped:  

<img src="{{ site.baseurl }}/images/2023-06-15-chatgpt-vs-peer-review-baudens-2.jpg" width="550" height="133" alt="Bauwens @ LinkedIn: Cheating reviewer dropped" title="Bauwens @ LinkedIn: Cheating reviewer dropped" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;">

It's actually too bad the cheating reviewer wasn't outed by name, for public shaming.
Academics (a) should know better about LLMs, given their students are faking homework with
them, and (b) should fulfill their review duties honestly in the first place.  


## The Weekend Conclusion  

Look, just don't use ChatGPT or other LLM engines for _anything_ serious!  They're
absolutely great for playing around, or for generating short texts that you're going to
fact-check at the level of _each and every word,_ but nothing else.  

Consult your cat, who probably has some excellent, if sarcastic, advice on this subject.
Or you could read what my cat, the Weekend Publisher, had to
say.  <sup id="fn3a">[[3]](#fn3)</sup>  

---

## Notes &amp; References  

<!--
<sup id="fn1a">[[1]](#fn1)</sup>

<a id="fn1">1</a>: ***, ["***"](***), *** [↩](#fn1a)  

<a href="{{ site.baseurl }}/images/***">
  <img src="{{ site.baseurl }}/images/***" width="400" height="***" alt="***" title="***" style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<a href="***">
  <img src="{{ site.baseurl }}/images/***" width="550" height="***" alt="***" title="***" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<iframe width="400" height="224" src="***" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;"></iframe>
-->

<a id="fn1">1</a>: [Weekend Editor](mailto:SomeWeekendReadingEditor@gmail.com), ["On ChatGPT and Its Ilk"]({{ site.baseurl }}/on-chatgpt/), [_Some Weekend Reading_]({{ site.baseurl }}/) blog, 2023-Feb-15. [↩](#fn1a)  

<a id="fn2">2</a>: R Bauwens, ["Untitled report of GPT-2 use in peer review"](https://www.linkedin.com/feed/update/urn:li:share:7046083155149103105/), [_LinkedIn_](https://www.linkedin.com/), 2023-April. [↩](#fn2a)  

<a id="fn3">3</a>: [Weekend Editor](mailto:SomeWeekendReadingEditor@gmail.com), ["ChatGPT and Francophone Misbranding"]({{ site.baseurl }}/misbranding-chatgpt-french/), [_Some Weekend Reading_]({{ site.baseurl }}/) blog, 2023-Mar-25. [↩](#fn3a)  
