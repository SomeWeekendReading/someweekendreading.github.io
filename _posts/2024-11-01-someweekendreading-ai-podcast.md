---
layout: post
title: An AI-Generated Podcast About This CLBTNR?!
tags: About ArtificialIntelligence NotableAndQuotable &Gammad;&Tau;&Phi;
comments: true
commentsClosed: true
---

Google has done a very silly thing: feed them some information, and they'll make a podcast
with 2 AI hosts 'discussing' it.  We fed them this Crummy Little Blog That Nobody Reads
(CLBTNR).  The results are&hellip; amusing?  

## They Made a What Now?  

<a href="{{ site.baseurl }}/images/ai-tuba.png"><img src="{{ site.baseurl }}/images/ai-tuba-thumb.jpg" width="400" height="533" alt="Image posted on Mastodon 2024-Oct-22 by @tveskov@mastodon.social: 2 girls in school uniforms, one blasting a tuba in the other's face, as a metaphor for companies forcing AI on consumers" title="Image posted on Mastodon 2024-Oct-22 by @tveskov@mastodon.social: 2 girls in school uniforms, one blasting a tuba in the other's face, as a metaphor for companies forcing AI on consumers" style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;"></a>
From Scott Alexander's _Astral Codex Ten_ November 2024 links post <sup id="fn1a">[[1]](#fn1)</sup>
came a link (item #17 on Scott's list) to
Nostalgebraist's peculiar experience <sup id="fn2a">[[2]](#fn2)</sup>
with a new 'service' from Google.  It seems that you can feed them whatever documents you
like, and get back an audio podcast of two AI hosts 'discussing' the
material. <sup id="fn3a">[[3]](#fn3)</sup>  

Nostaglebraist, after feeding it 2 of his novels, has this to say about the result:  

> These podcast episodes are... they're not, uh, __good.__  In fact, they're terrible – so
> cringe-y and inane that I find them painful to listen to.  
>  
> But &ndash; unlike with the "AI-generated content" of even the __very recent past__ &ndash;
> the problem with this stuff isn't that it's unrealistic.  It's perfectly realistic.  The
> podcasters sound like real people!  Everything they say is perfectly coherent!  It's
> just coherently &hellip; __bad.__  
>  
> It's a __perfect__ imitation of superficial, formulaic, cringe-y media commentary podcasts.
> The content isn't good, but it's a type of bad content that exists, and the AI mimics it
> expertly.  
>  
> The badness is authentic. &hellip;  
>  
> But even if no one especially likes this kind of slop, it's highly __inoffensive__ &ndash;
> palatable to everyone, not likely to confuse anyone or piss anyone off &ndash; and so it's
> what we get, for now, while these companies are still cautiously testing the waters.)  
>  
> &hellip; Painfully basic when it's not actually inaccurate.  

That's about what we would expect: expertly inoffensive, but having at best a casual
relationship with truth.  

It's not as though Google didn't warn us; in _tiny_ type at the bottom of the Notebook LM
page, it says:  

> NotebookLM may still sometimes give inaccurate responses, so you may want to confirm any
> facts independently.

Ya _think?!_  


## The Acid Test  

Ok, you know what's coming next, right?  

Rashly, I fed it this very CLBTNR.  All of it.  Here's the summary it generated:  

> __Summary__  
>  
> The provided text consists of blog posts written by a retired scientist, who describes
> his observations and opinions on a wide range of topics, including the 2024 US election,
> the COVID-19 pandemic, Russia's invasion of Ukraine, and scientific advancements. He
> expresses his frustrations with the state of politics in the United States, highlighting
> his concerns about Republican tactics and the spread of misinformation. The blogger
> frequently discusses scientific data and research, using his expertise to analyze events
> and share insights on various topics. He also incorporates personal anecdotes and humorous
> observations, providing a unique and engaging perspective on the world.  

Ok, I guess that's not exactly _wrong_&hellip;  

<audio src="/assets/2024-11-01-someweekendreading-ai-podcast.mp3" controls preload style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;"></audio>
The original is a giant .wav file.  But I've downloaded it for archival purposes and
converted it to a much smaller .mp3 file, because I'm not stupid.  Here's the 13 minute
'podcast' of 2 AI-generated characters attempting to discuss this CLBTNR.  

A number of things are, of course, just _wrong:_  
- I didn't get vaccinated in March of 2020; there were no COVID-19 vaccines in March
  of 2020.  That was a year later in 2021.  
- The blog didn't start in February of 2020, either.  Formally, it started in July 2020.
  ("Formally": in the sense that the first upload was in September, but back-dated to the
  first day of retirement in July.)  
  
Much of the rest is not wrong _per se,_ just vapid, superficial, and inconsequential.  But
the imitation of cringe-inducing mainstream media talk radio or podcasting&hellip; that's
spot-on perfect.  

I mean, I'm as vain as the next person, so their generally positive view of this CLBTNR
made me feel sorta good&hellip; until I slapped myself silly with the fact that there's
_nothing there_ that can even understand, let alone have a respectable opinion.  I might
as well feel good about my dishwasher.  (It _is_ a good dishwasher, _for washing dishes._
But I don't ask it for opinions on what I read or write.)  


## The Weekend Conclusion  

Vapid.  Inconsequential.  Only a casual relationship to the truth, at best.  Sanitized to
be almost aggressively inoffensive.  

Again, look at the tuba picture above: exactly _who_ needs this and who would be rash
enough to trust the output?  Even Google says it lies to us, so you have to fact-check
every dang thing it says.  Surely it's less work to summarize the material for yourself,
rather than listen to over-persuasive voices that occasionally lie convincingly?  

[(_Ceterum censeo, Trump incarcerandam esse._)]({{ site.baseurl }}/trump-danger-test/#the-weekend-conclusion)  

## Addendum 2024-Nov-02: Le Mot Juste  

Pablo, responding by email, came up with the perfect description:  

> Feels like Muzak in spoken form.  

Le mot juste, c'est celui l&agrave;!  

---

## Notes &amp; References  

<!--
<sup id="fn1a">[[1]](#fn1)</sup>

<a id="fn1">1</a>: ***, ["***"](***), *** DOI: [***](***). [↩](#fn1a)  

<a href="{{ site.baseurl }}/images/***">
  <img src="{{ site.baseurl }}/images/***" width="400" height="***" alt="***" title="***" style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<a href="***">
  <img src="{{ site.baseurl }}/images/***" width="550" height="***" alt="***" title="***" style="margin: 3px 3px 3px 3px; border: 1px solid #000000;">
</a>

<iframe width="400" height="224" src="***" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="float: right; margin: 3px 3px 3px 3px; border: 1px solid #000000;"></iframe>
-->

<a id="fn1">1</a>: Scott Alexander Siskind, ["Links For November 2024"](https://www.astralcodexten.com/p/links-for-november-2024#:~:text=17%3A%20Nostalgebraist,Existential%20Meltdown.), _Astral Codex Ten_ blog, 2024-Nov-01.  

Item #17 is the relevant bit, in case the link doesn't take you there directly. [↩](#fn1a)  

<a id="fn2">2</a>: 'Nostalgebraist', ["In the Other Uncanny Valley: AI Voice News at Google"](https://www.tumblr.com/nostalgebraist/762931781730271232/in-other-uncanny-valley-ai-voice-news-google), _trees are harlequins, words are harlequins_ (Nostalgebraist Tumblr blog), 2024-Sep-29. [↩](#fn2a)  

<a id="fn3">3</a>: Google Staff, ["Notebook LM"](https://notebooklm.google.com/), Google services, downloaded 2024-Nov-01. [↩](#fn3a)  
